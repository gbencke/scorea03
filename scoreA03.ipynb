{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Score de pagamentos Itau Cartões A03"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esse notebook tem por objetivo criar um modelo de classificação de probabilidade de pagamentos para o segmento A03 da carteira Itau Cartões da Zanc.\n",
    "Faremos uso de uma base de cerca de 100 mil cpfs que tiveram permanencia de 45 completos dentro da empresa.\n",
    "Nosso target é conseguir distinguir quem tem mais chances de recuperação de crédito de quem não tem.\n",
    "\n",
    "Hoje já obtivemos algum resultado utilizando Logistic Regression através da ferramenta Orange.\n",
    "A tarefa inicial será de transportar para esse notebookk com código python o que foi feito no Orange.\n",
    "Na seqüência será proposto uma outra abordagem utilizando Gradient Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparação dos dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importando módulos necessários"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # Sem ele não somos ninguém\n",
    "import time # Para medir o tempo de execução dos modelos\n",
    "import pandas as pd # Para carregar os dados em um datafram\n",
    "from sklearn.utils import resample # Para balancear os dados\n",
    "from sklearn.impute import SimpleImputer # Para preencher os campos que estivem com valores nulos\n",
    "from sklearn.preprocessing import MinMaxScaler # Para normalização dos campos numéricos\n",
    "from sklearn.linear_model import LogisticRegression # Para instanciar o modelo de Regressão Logística\n",
    "from sklearn.ensemble import GradientBoostingClassifier # Para instanciar o modelo de Gradient Boosting\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, RandomizedSearchCV # Para avaliação dos modelos\n",
    "import pickle # Para salvar o modelo para uso futuro\n",
    "import joblib # Para salvar o modelo para uso futuro\n",
    "from Tratamentos import converte_publico, trata_loja"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importando os dados para um df pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos importar o dataframe utilizando a funcao read csv padrão do pandas, analisando as colunas, tipos e valores nulos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LOJA</th>\n",
       "      <th>renda</th>\n",
       "      <th>cpf_cnpj</th>\n",
       "      <th>scorecontratante</th>\n",
       "      <th>dataentrada</th>\n",
       "      <th>validadecampanha</th>\n",
       "      <th>atrasocongelado</th>\n",
       "      <th>valorcartacampanha</th>\n",
       "      <th>vlclusters</th>\n",
       "      <th>status_boletagem</th>\n",
       "      <th>data_status_boletagem</th>\n",
       "      <th>desconto</th>\n",
       "      <th>bandeira</th>\n",
       "      <th>publico</th>\n",
       "      <th>matriz</th>\n",
       "      <th>Pagamentos</th>\n",
       "      <th>Acionamentos</th>\n",
       "      <th>Valor Pago</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CARTÃO PRIV LBL FIC ASSAI</td>\n",
       "      <td>0</td>\n",
       "      <td>74713</td>\n",
       "      <td>425</td>\n",
       "      <td>21/02/2019 00:00</td>\n",
       "      <td>17/04/2019</td>\n",
       "      <td>253</td>\n",
       "      <td>1582.10</td>\n",
       "      <td>1894.25</td>\n",
       "      <td>BOLETAR_A_PARTIR_</td>\n",
       "      <td>17/03/2019</td>\n",
       "      <td>50.72</td>\n",
       "      <td>FC</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CARTÃO EXTRA 2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>333751</td>\n",
       "      <td>428</td>\n",
       "      <td>25/04/2019 00:00</td>\n",
       "      <td>19/06/2019</td>\n",
       "      <td>192</td>\n",
       "      <td>392.90</td>\n",
       "      <td>439.42</td>\n",
       "      <td>BOLETAR_A_PARTIR_</td>\n",
       "      <td>19/05/2019</td>\n",
       "      <td>33.60</td>\n",
       "      <td>FC</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MAGAZINE LUIZA/LUIZACRED FLEX</td>\n",
       "      <td>0</td>\n",
       "      <td>676527</td>\n",
       "      <td>343</td>\n",
       "      <td>02/03/2019 00:00</td>\n",
       "      <td>26/04/2019</td>\n",
       "      <td>197</td>\n",
       "      <td>1069.87</td>\n",
       "      <td>1353.72</td>\n",
       "      <td>BOLETAR_A_PARTIR_</td>\n",
       "      <td>26/03/2019</td>\n",
       "      <td>42.52</td>\n",
       "      <td>LC</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CARTÃO EXTRA 2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>919799</td>\n",
       "      <td>353</td>\n",
       "      <td>13/12/2018 00:00</td>\n",
       "      <td>06/02/2019</td>\n",
       "      <td>369</td>\n",
       "      <td>1002.21</td>\n",
       "      <td>1717.83</td>\n",
       "      <td>BOLETAR_A_PARTIR_</td>\n",
       "      <td>06/01/2019</td>\n",
       "      <td>71.04</td>\n",
       "      <td>FC</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CARTÃO EXTRA 2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1140140</td>\n",
       "      <td>371</td>\n",
       "      <td>18/04/2019 00:00</td>\n",
       "      <td>12/06/2019</td>\n",
       "      <td>307</td>\n",
       "      <td>874.41</td>\n",
       "      <td>988.66</td>\n",
       "      <td>BOLETAR_A_PARTIR_</td>\n",
       "      <td>12/05/2019</td>\n",
       "      <td>53.04</td>\n",
       "      <td>FC</td>\n",
       "      <td>ElegÃ­vel ExceÃ§Ã£o</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            LOJA  renda  cpf_cnpj  scorecontratante  \\\n",
       "0     CARTÃO PRIV LBL FIC ASSAI      0     74713               425   \n",
       "1              CARTÃO EXTRA 2.0      0    333751               428   \n",
       "2  MAGAZINE LUIZA/LUIZACRED FLEX      0    676527               343   \n",
       "3              CARTÃO EXTRA 2.0      0    919799               353   \n",
       "4              CARTÃO EXTRA 2.0      0   1140140               371   \n",
       "\n",
       "        dataentrada validadecampanha  atrasocongelado  valorcartacampanha  \\\n",
       "0  21/02/2019 00:00       17/04/2019              253             1582.10   \n",
       "1  25/04/2019 00:00       19/06/2019              192              392.90   \n",
       "2  02/03/2019 00:00       26/04/2019              197             1069.87   \n",
       "3  13/12/2018 00:00       06/02/2019              369             1002.21   \n",
       "4  18/04/2019 00:00       12/06/2019              307              874.41   \n",
       "\n",
       "   vlclusters   status_boletagem data_status_boletagem  desconto bandeira  \\\n",
       "0     1894.25  BOLETAR_A_PARTIR_            17/03/2019     50.72       FC   \n",
       "1      439.42  BOLETAR_A_PARTIR_            19/05/2019     33.60       FC   \n",
       "2     1353.72  BOLETAR_A_PARTIR_            26/03/2019     42.52       LC   \n",
       "3     1717.83  BOLETAR_A_PARTIR_            06/01/2019     71.04       FC   \n",
       "4      988.66  BOLETAR_A_PARTIR_            12/05/2019     53.04       FC   \n",
       "\n",
       "               publico  matriz  Pagamentos  Acionamentos Valor Pago  \n",
       "0                    0       3           0            26        NaN  \n",
       "1                    0       4           0             0        NaN  \n",
       "2                    0       3           0             5        NaN  \n",
       "3                    0       3           0             7        NaN  \n",
       "4  ElegÃ­vel ExceÃ§Ã£o       3           0             1        NaN  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(r\"data\\prever_novo.csv\", encoding=\"latin1\", delimiter=\";\", decimal = \",\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(111420, 15)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LOJA                      object\n",
       "renda                      int64\n",
       "cpf_cnpj                   int64\n",
       "scorecontratante           int64\n",
       "dataentrada               object\n",
       "validadecampanha          object\n",
       "atrasocongelado            int64\n",
       "valorcartacampanha       float64\n",
       "vlclusters               float64\n",
       "status_boletagem          object\n",
       "data_status_boletagem     object\n",
       "desconto                 float64\n",
       "bandeira                  object\n",
       "publico                   object\n",
       "matriz                     int64\n",
       "Pagamentos                 int64\n",
       "Acionamentos               int64\n",
       "Valor Pago                object\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LOJA                          0\n",
       "renda                         0\n",
       "cpf_cnpj                      0\n",
       "scorecontratante              0\n",
       "dataentrada                   0\n",
       "validadecampanha              0\n",
       "atrasocongelado               0\n",
       "valorcartacampanha            0\n",
       "vlclusters                    0\n",
       "status_boletagem              0\n",
       "data_status_boletagem         0\n",
       "desconto                      0\n",
       "bandeira                      0\n",
       "publico                       0\n",
       "matriz                        0\n",
       "Pagamentos                    0\n",
       "Acionamentos                  0\n",
       "Valor Pago               109295\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalizando campos numéricos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "escalador_vlrcartacampanha = MinMaxScaler()\n",
    "escalador_vlrccluster = MinMaxScaler()\n",
    "escalador_vlrdesconto = MinMaxScaler()\n",
    "df['valorcartacampanha_s'] = escalador_vlrcartacampanha.fit_transform(df[['valorcartacampanha']].values)\n",
    "df['vlclusters_s'] = escalador_vlrccluster.fit_transform(df[['vlclusters']].values)\n",
    "df['desconto_s'] = escalador_vlrdesconto.fit_transform(df[['desconto']].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tratando Loja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OUTROS                           44677\n",
       "MAGAZINE LUIZA/LUIZACRED FLEX    32317\n",
       "HIPERCARD                        14884\n",
       "CREDICARD CLASSICOS               4567\n",
       "CARTAO PL FIC CB S/P              3402\n",
       "ITAUCARD 2.0 CANAIS DIRETOS       3080\n",
       "OPERACOES CREDITO CREDICARD       2721\n",
       "CARTAO PL FIC EXTRA S/P           2154\n",
       "TAM ITAUCARD 2.0                  1450\n",
       "CARTAO PL EMBANDEIRADO MARISA     1435\n",
       "CARTAO PL FIC EXTRA BAND          1161\n",
       "Name: LOJA, dtype: int64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def trata_loja(x):\n",
    "    lojas = ['CARTÃO EXTRA 2.0',\n",
    "             'CARTÃO MARISA 2.0',\n",
    "             'CARTAO PL EMBANDEIRADO MARISA',\n",
    "             'CARTAO PL FIC CB S/P',\n",
    "             'CARTAO PL FIC EXTRA BAND',\n",
    "             'CARTAO PL FIC EXTRA S/P',\n",
    "             'CARTÃO PONTO FRIO 2.0',\n",
    "             'CARTÃO PRIV LBL FIC ASSAI',\n",
    "             'CARTÃO WALMART 2.0',\n",
    "             'CREDICARD CLASSICOS',\n",
    "             'HIPERCARD',\n",
    "             'ITAUCARD 2.0 CANAIS DIRETOS',\n",
    "             'MAGAZINE LUIZA/LUIZACRED FLEX',\n",
    "             'OPERACOES CREDITO CREDICARD',\n",
    "             'OUTROS',\n",
    "             'TAM ITAUCARD 2.0']\n",
    "    if x in lojas:\n",
    "        return x\n",
    "    else:\n",
    "        return 'OUTROS'\n",
    "df['LOJA'] = df['LOJA'].apply(trata_loja)\n",
    "df['LOJA'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tratando público"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                         70152\n",
       "elegivel_excecao          23983\n",
       "ElegÃ­vel ExceÃ§Ã£o       11902\n",
       "Elegivel Excecao           2639\n",
       "alto_atrito                1939\n",
       "Alto Atrito                1090\n",
       "Eleg?Â¡vel Exce?Âº?Ãºo      142\n",
       "883000140672                  1\n",
       "Name: publico, dtype: int64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['publico'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nao_definido        70153\n",
       "elegivel_excecao    38666\n",
       "alto_atrito          3029\n",
       "Name: publico, dtype: int64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def converte_publico(x):\n",
    "    if x==\"Eleg?¡vel Exce?º?úo\" or x==\"Elegível Exceção\" or x==\"Elegivel Excecao\" or x==\"ElegÃ­vel ExceÃ§Ã£o\" or x==\"Eleg?Â¡vel Exce?Âº?Ãºo\":\n",
    "        return \"elegivel_excecao\"\n",
    "    elif x==\"Alto Atrito\":\n",
    "        return \"alto_atrito\"\n",
    "    elif x==\"0\" or x==\"883000140672\":\n",
    "        return \"nao_definido\"\n",
    "    else:\n",
    "        return x\n",
    "\n",
    "df['publico'] = df['publico'].apply(converte_publico)\n",
    "df['publico'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transformando colunas categóricas em binárias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "colunas_treino = ['LOJA',\n",
    "                  'renda',\n",
    "                  'scorecontratante',\n",
    "                  'atrasocongelado',\n",
    "                  'valorcartacampanha_s',\n",
    "                  'vlclusters_s',\n",
    "                  'status_boletagem',\n",
    "                  'desconto_s',\n",
    "                  'bandeira',\n",
    "                  'publico',\n",
    "                  'matriz'\n",
    "                 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummies = pd.get_dummies(df[colunas_treino])\n",
    "dropado = df.drop(colunas_treino,axis=1)\n",
    "df = pd.concat([dummies,dropado], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Separando treino e teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    109295\n",
       "1      2553\n",
       "Name: Pagamentos, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Pagamentos'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    2553\n",
       "0    2533\n",
       "Name: Pagamentos, dtype: int64"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_maioria = df[df.Pagamentos==0]\n",
    "df_minoria = df[df.Pagamentos==1]\n",
    "df_maioria_randomizado = resample(df_maioria, \n",
    "                                 replace=True,     \n",
    "                                 n_samples=2533,    \n",
    "                                 random_state=123)\n",
    "df_balanceado = pd.concat([df_maioria_randomizado, df_minoria])\n",
    "df_balanceado.Pagamentos.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['renda', 'scorecontratante', 'atrasocongelado', 'valorcartacampanha_s',\n",
       "       'vlclusters_s', 'desconto_s', 'matriz',\n",
       "       'LOJA_CARTAO PL EMBANDEIRADO MARISA', 'LOJA_CARTAO PL FIC CB S/P',\n",
       "       'LOJA_CARTAO PL FIC EXTRA BAND', 'LOJA_CARTAO PL FIC EXTRA S/P',\n",
       "       'LOJA_CREDICARD CLASSICOS', 'LOJA_HIPERCARD',\n",
       "       'LOJA_ITAUCARD 2.0 CANAIS DIRETOS',\n",
       "       'LOJA_MAGAZINE LUIZA/LUIZACRED FLEX',\n",
       "       'LOJA_OPERACOES CREDITO CREDICARD', 'LOJA_OUTROS',\n",
       "       'LOJA_TAM ITAUCARD 2.0', 'status_boletagem_0',\n",
       "       'status_boletagem_BOLETAR_A_PARTIR_',\n",
       "       'status_boletagem_BOLETAR_A_VONTADE', 'bandeira_CC', 'bandeira_CR',\n",
       "       'bandeira_FA', 'bandeira_FC', 'bandeira_FT', 'bandeira_HC',\n",
       "       'bandeira_LC', 'bandeira_MA', 'publico_alto_atrito',\n",
       "       'publico_elegivel_excecao', 'publico_nao_definido'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummies.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = df_balanceado.Pagamentos.values\n",
    "X_train = df_balanceado[dummies.columns].values\n",
    "y_test = df.Pagamentos.values\n",
    "X_test = df[dummies.columns].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Treinando e predizendo com LogReg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.649833 using {'C': 3.5, 'dual': False, 'max_iter': 100}\n",
      "Execution time: 6.564402103424072 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\joaoc\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "param_grid_lr = {\n",
    "    'dual': [True,False],\n",
    "    'max_iter': [100,110,120,130,140],\n",
    "    'C': [1.0,1.5,2.0,2.5,3.5]\n",
    "}\n",
    "lr = LogisticRegression()\n",
    "grid_lr = GridSearchCV(estimator=lr, param_grid=param_grid_lr, cv=5, scoring='roc_auc', n_jobs=-1)\n",
    "start_time = time.time()\n",
    "grid_result = grid_lr.fit(X_train, y_train)\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "print(\"Execution time: \" + str((time.time() - start_time)) + ' ms')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = grid_result.predict_proba(X_test)\n",
    "df_predicted = df_dummies\n",
    "df_predicted['pagamentos real'] = y_test\n",
    "df_predicted['prob prevista'] = pred[:,1]\n",
    "df_predicted.to_csv('logreg_predicted.csv', decimal=',', sep=\";\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Treinando e predizendo com XgBoosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.679539 using {'min_samples_leaf': 5, 'n_estimators': 200, 'subsample': 0.6}\n",
      "Execution time: 150.36838054656982 ms\n"
     ]
    }
   ],
   "source": [
    "param_grid_xg = {\n",
    "        'n_estimators':[100,200,400,600],\n",
    "        'min_samples_leaf':[5,10,20],\n",
    "        'subsample': [0.6, 0.8, 1.0]\n",
    "        }\n",
    "xg = GradientBoostingClassifier(learning_rate=0.02)\n",
    "grid_xg = GridSearchCV(estimator=xg, param_grid=param_grid_xg, cv=5, scoring='roc_auc', n_jobs=-1)\n",
    "grid_result_xg = grid_xg.fit(X_train, y_train)\n",
    "print(\"Best: %f using %s\" % (grid_result_xg.best_score_, grid_result_xg.best_params_))\n",
    "print(\"Execution time: \" + str((time.time() - start_time)) + ' ms')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = grid_result_xg.predict_proba(X_test)\n",
    "df_predicted = df\n",
    "df_predicted['prob prevista'] = pred[:,1]\n",
    "df_predicted.to_csv(r'data\\xgboost_train_result_predict.csv', decimal=',', sep=\";\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Salvando os Scalers e o Xgboosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['models\\\\xgboosting_a03.pkl']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(escalador_vlrcartacampanha, r\"models\\scaler_vlrcartacampanha_a03.pkl\")\n",
    "joblib.dump(escalador_vlrccluster, r\"models\\scaler_vlrcluster_a03.pkl\")\n",
    "joblib.dump(escalador_vlrdesconto, r\"models\\scaler_vlrdesconto_a03.pkl\")\n",
    "joblib.dump(grid_result_xg, r\"models\\xgboosting_a03.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### To-do"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. ~~Antes de gerar as dummies montar uma transformação para a coluna publico corrigindo: 'publico_Alto Atrito', 'publico_Eleg?¡vel Exce?º?úo', 'publico_Elegivel Excecao', 'publico_Elegível Exceção','publico_Não definido', 'publico_alto_atrito','publico_elegivel_excecao'~~\n",
    "2. ~~Ajutar a métrica para ROC~~\n",
    "3. ~~Rodar GridSearch para os hiperparâmetros da regLog e Xgboost otimizando ROC~~\n",
    "4. ~~Selecionar o modelo e montar .py para predizer através do DW~~\n",
    "5. Integrar com DW para criar uma coluna com a probabilidade prevista\n",
    "6. Criar tratamento para nulos, pois eles foram retirados nessa amostra e será necessário para treinar no futuro\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
