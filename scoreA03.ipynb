{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Score de pagamentos Itau Cartões A03"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esse notebook tem por objetivo criar um modelo de classificação de probabilidade de pagamentos para o segmento A03 da carteira Itau Cartões da Zanc.\n",
    "Faremos uso de uma base de cerca de 100 mil cpfs que tiveram permanencia de 45 completos dentro da empresa.\n",
    "Nosso target é conseguir distinguir quem tem mais chances de recuperação de crédito de quem não tem.\n",
    "\n",
    "Hoje já obtivemos algum resultado utilizando Logistic Regression através da ferramenta Orange.\n",
    "A tarefa inicial será de transportar para esse notebookk com código python o que foi feito no Orange.\n",
    "Na seqüência será proposto uma outra abordagem utilizando Gradient Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparação dos dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importando módulos necessários"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # Sem ele não somos ninguém\n",
    "import time # Para medir o tempo de execução dos modelos\n",
    "import pandas as pd # Para carregar os dados em um datafram\n",
    "from sklearn.utils import resample # Para balancear os dados\n",
    "from sklearn.impute import SimpleImputer # Para preencher os campos que estivem com valores nulos\n",
    "from sklearn.preprocessing import MinMaxScaler # Para normalização dos campos numéricos\n",
    "from sklearn.linear_model import LogisticRegression # Para instanciar o modelo de Regressão Logística\n",
    "from sklearn.ensemble import GradientBoostingClassifier # Para instanciar o modelo de Gradient Boosting\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, RandomizedSearchCV # Para avaliação dos modelos\n",
    "import pickle # Para salvar o modelo para uso futuro\n",
    "import joblib # Para salvar o modelo para uso futuro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importando os dados para um df pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos importar o dataframe utilizando a funcao read csv padrão do pandas, analisando as colunas, tipos e valores nulos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data_status_boletagem</th>\n",
       "      <th>LOJA</th>\n",
       "      <th>LOJA TRATADO</th>\n",
       "      <th>scorecontratante</th>\n",
       "      <th>dataentrada</th>\n",
       "      <th>validadecampanha</th>\n",
       "      <th>atrasocongelado</th>\n",
       "      <th>valorcartacampanha</th>\n",
       "      <th>vlclusters</th>\n",
       "      <th>status_boletagem</th>\n",
       "      <th>desconto</th>\n",
       "      <th>bandeira</th>\n",
       "      <th>publico</th>\n",
       "      <th>matriz</th>\n",
       "      <th>Pagamentos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>ITAUCARD HIPER 2.0</td>\n",
       "      <td>OUTROS</td>\n",
       "      <td>242</td>\n",
       "      <td>22/02/2019 00:00</td>\n",
       "      <td>18/04/2019</td>\n",
       "      <td>204</td>\n",
       "      <td>207.85</td>\n",
       "      <td>276.47</td>\n",
       "      <td>BOLETAR_A_VONTADE</td>\n",
       "      <td>48.19</td>\n",
       "      <td>CC</td>\n",
       "      <td>Não definido</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>CARTÃO EXTRA 2.0</td>\n",
       "      <td>CARTÃO EXTRA 2.0</td>\n",
       "      <td>246</td>\n",
       "      <td>15/11/2018 00:00</td>\n",
       "      <td>09/01/2019</td>\n",
       "      <td>304</td>\n",
       "      <td>1232.75</td>\n",
       "      <td>2612.60</td>\n",
       "      <td>BOLETAR_A_VONTADE</td>\n",
       "      <td>71.55</td>\n",
       "      <td>FC</td>\n",
       "      <td>Não definido</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>MAGAZINE LUIZA/LUIZACRED FLEX</td>\n",
       "      <td>MAGAZINE LUIZA/LUIZACRED FLEX</td>\n",
       "      <td>248</td>\n",
       "      <td>17/11/2018 00:00</td>\n",
       "      <td>11/01/2019</td>\n",
       "      <td>361</td>\n",
       "      <td>1106.69</td>\n",
       "      <td>2407.57</td>\n",
       "      <td>BOLETAR_A_VONTADE</td>\n",
       "      <td>77.65</td>\n",
       "      <td>LC</td>\n",
       "      <td>Não definido</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>MAGAZINE LUIZA/LUIZACRED FLEX</td>\n",
       "      <td>MAGAZINE LUIZA/LUIZACRED FLEX</td>\n",
       "      <td>253</td>\n",
       "      <td>22/04/2019 00:00</td>\n",
       "      <td>14/06/2019</td>\n",
       "      <td>367</td>\n",
       "      <td>2511.74</td>\n",
       "      <td>9817.66</td>\n",
       "      <td>BOLETAR_A_VONTADE</td>\n",
       "      <td>86.74</td>\n",
       "      <td>LC</td>\n",
       "      <td>Não definido</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>CARTÃO WALMART 2.0</td>\n",
       "      <td>CARTÃO WALMART 2.0</td>\n",
       "      <td>253</td>\n",
       "      <td>15/02/2019 00:00</td>\n",
       "      <td>11/04/2019</td>\n",
       "      <td>362</td>\n",
       "      <td>1320.07</td>\n",
       "      <td>2918.04</td>\n",
       "      <td>BOLETAR_A_VONTADE</td>\n",
       "      <td>77.28</td>\n",
       "      <td>HC</td>\n",
       "      <td>Não definido</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  data_status_boletagem                           LOJA  \\\n",
       "0                     0             ITAUCARD HIPER 2.0   \n",
       "1                     0               CARTÃO EXTRA 2.0   \n",
       "2                     0  MAGAZINE LUIZA/LUIZACRED FLEX   \n",
       "3                     0  MAGAZINE LUIZA/LUIZACRED FLEX   \n",
       "4                     0             CARTÃO WALMART 2.0   \n",
       "\n",
       "                    LOJA TRATADO  scorecontratante       dataentrada  \\\n",
       "0                         OUTROS               242  22/02/2019 00:00   \n",
       "1               CARTÃO EXTRA 2.0               246  15/11/2018 00:00   \n",
       "2  MAGAZINE LUIZA/LUIZACRED FLEX               248  17/11/2018 00:00   \n",
       "3  MAGAZINE LUIZA/LUIZACRED FLEX               253  22/04/2019 00:00   \n",
       "4             CARTÃO WALMART 2.0               253  15/02/2019 00:00   \n",
       "\n",
       "  validadecampanha  atrasocongelado  valorcartacampanha  vlclusters  \\\n",
       "0       18/04/2019              204              207.85      276.47   \n",
       "1       09/01/2019              304             1232.75     2612.60   \n",
       "2       11/01/2019              361             1106.69     2407.57   \n",
       "3       14/06/2019              367             2511.74     9817.66   \n",
       "4       11/04/2019              362             1320.07     2918.04   \n",
       "\n",
       "    status_boletagem  desconto bandeira       publico  matriz  Pagamentos  \n",
       "0  BOLETAR_A_VONTADE     48.19       CC  Não definido       3           0  \n",
       "1  BOLETAR_A_VONTADE     71.55       FC  Não definido       4           0  \n",
       "2  BOLETAR_A_VONTADE     77.65       LC  Não definido       3           0  \n",
       "3  BOLETAR_A_VONTADE     86.74       LC  Não definido       3           0  \n",
       "4  BOLETAR_A_VONTADE     77.28       HC  Não definido       3           0  "
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data\\train_set.csv\", encoding=\"latin1\", delimiter=\";\", decimal = \",\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(111420, 15)"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "data_status_boletagem     object\n",
       "LOJA                      object\n",
       "LOJA TRATADO              object\n",
       "scorecontratante           int64\n",
       "dataentrada               object\n",
       "validadecampanha          object\n",
       "atrasocongelado            int64\n",
       "valorcartacampanha       float64\n",
       "vlclusters               float64\n",
       "status_boletagem          object\n",
       "desconto                 float64\n",
       "bandeira                  object\n",
       "publico                   object\n",
       "matriz                     int64\n",
       "Pagamentos                 int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "data_status_boletagem    0\n",
       "LOJA                     0\n",
       "LOJA TRATADO             0\n",
       "scorecontratante         0\n",
       "dataentrada              0\n",
       "validadecampanha         0\n",
       "atrasocongelado          0\n",
       "valorcartacampanha       0\n",
       "vlclusters               0\n",
       "status_boletagem         0\n",
       "desconto                 0\n",
       "bandeira                 0\n",
       "publico                  0\n",
       "matriz                   0\n",
       "Pagamentos               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df[df['valorcartacampanha'] < 2500] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalizando campos numéricos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "escalador_vlrcartacampanha = MinMaxScaler()\n",
    "escalador_vlrccluster = MinMaxScaler()\n",
    "escalador_vlrdesconto = MinMaxScaler()\n",
    "df[['valorcartacampanha']] = escalador_vlrcartacampanha.fit_transform(df[['valorcartacampanha']].values)\n",
    "df[['vlclusters']] = escalador_vlrccluster.fit_transform(df[['vlclusters']].values)\n",
    "df[['desconto']] = escalador_vlrdesconto.fit_transform(df[['desconto']].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dropando colunas de data e coluna já mapeada (Loja)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         22/02/2019 00:00\n",
       "1         15/11/2018 00:00\n",
       "2         17/11/2018 00:00\n",
       "3         22/04/2019 00:00\n",
       "4         15/02/2019 00:00\n",
       "5         30/11/2018 00:00\n",
       "6         09/03/2019 00:00\n",
       "7         02/03/2019 00:00\n",
       "8         21/02/2019 00:00\n",
       "9         25/01/2019 00:00\n",
       "10        14/02/2019 00:00\n",
       "11        22/02/2019 00:00\n",
       "12        30/03/2019 00:00\n",
       "13        22/03/2019 00:00\n",
       "14        17/01/2019 00:00\n",
       "15        21/02/2019 00:00\n",
       "16        19/01/2019 00:00\n",
       "17        05/04/2019 00:00\n",
       "18        14/03/2019 00:00\n",
       "19        16/03/2019 00:00\n",
       "20        24/01/2019 00:00\n",
       "21        21/03/2019 00:00\n",
       "22        06/02/2019 00:00\n",
       "23        10/01/2019 00:00\n",
       "24        29/12/2018 00:00\n",
       "25        23/11/2018 00:00\n",
       "26        27/02/2019 00:00\n",
       "27        22/02/2019 00:00\n",
       "28        14/03/2019 00:00\n",
       "29        05/01/2019 00:00\n",
       "                ...       \n",
       "111390    07/12/2018 00:00\n",
       "111391    07/12/2018 00:00\n",
       "111392    07/12/2018 00:00\n",
       "111393    29/03/2019 00:00\n",
       "111394    07/12/2018 00:00\n",
       "111395    07/12/2018 00:00\n",
       "111396    07/12/2018 00:00\n",
       "111397    07/12/2018 00:00\n",
       "111398    07/12/2018 00:00\n",
       "111399    07/12/2018 00:00\n",
       "111400    07/12/2018 00:00\n",
       "111401    07/12/2018 00:00\n",
       "111402    07/12/2018 00:00\n",
       "111403    07/12/2018 00:00\n",
       "111404    07/12/2018 00:00\n",
       "111405    07/12/2018 00:00\n",
       "111406    29/03/2019 00:00\n",
       "111407    07/12/2018 00:00\n",
       "111408    07/12/2018 00:00\n",
       "111409    07/12/2018 00:00\n",
       "111410    29/03/2019 00:00\n",
       "111411    07/12/2018 00:00\n",
       "111412    07/12/2018 00:00\n",
       "111413    07/12/2018 00:00\n",
       "111414    07/12/2018 00:00\n",
       "111415    07/12/2018 00:00\n",
       "111416    07/12/2018 00:00\n",
       "111417    07/12/2018 00:00\n",
       "111418    07/12/2018 00:00\n",
       "111419    07/12/2018 00:00\n",
       "Name: dataentrada, Length: 111420, dtype: object"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.pop('data_status_boletagem')\n",
    "df.pop('LOJA')\n",
    "df.pop('validadecampanha')\n",
    "df.pop('dataentrada')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ajustando valores da coluna público"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Não definido           69862\n",
       "elegivel_excecao       23938\n",
       "Elegível Exceção       11820\n",
       "Elegivel Excecao        2630\n",
       "alto_atrito             1939\n",
       "Alto Atrito             1089\n",
       "Eleg?¡vel Exce?º?úo      142\n",
       "Name: publico, dtype: int64"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['publico'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Não definido        69862\n",
       "elegivel_excecao    38530\n",
       "alto_atrito          3028\n",
       "Name: publico, dtype: int64"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def converte_publico(x):\n",
    "    if x==\"Eleg?¡vel Exce?º?úo\" or x==\"Elegível Exceção\" or x==\"Elegivel Excecao\":\n",
    "        return \"elegivel_excecao\"\n",
    "    elif x==\"Alto Atrito\":\n",
    "        return \"alto_atrito\"\n",
    "    else:\n",
    "        return x\n",
    "\n",
    "df['publico'] = df['publico'].apply(converte_publico)\n",
    "df['publico'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transformando colunas categóricas em binárias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['scorecontratante', 'atrasocongelado', 'valorcartacampanha',\n",
       "       'vlclusters', 'desconto', 'matriz', 'Pagamentos',\n",
       "       'LOJA TRATADO_CARTAO PL EMBANDEIRADO MARISA',\n",
       "       'LOJA TRATADO_CARTAO PL FIC CB S/P',\n",
       "       'LOJA TRATADO_CARTAO PL FIC EXTRA BAND',\n",
       "       'LOJA TRATADO_CARTAO PL FIC EXTRA S/P', 'LOJA TRATADO_CARTÃO EXTRA 2.0',\n",
       "       'LOJA TRATADO_CARTÃO MARISA 2.0', 'LOJA TRATADO_CARTÃO PONTO FRIO 2.0',\n",
       "       'LOJA TRATADO_CARTÃO PRIV LBL FIC ASSAI',\n",
       "       'LOJA TRATADO_CARTÃO WALMART 2.0', 'LOJA TRATADO_CREDICARD CLASSICOS',\n",
       "       'LOJA TRATADO_HIPERCARD', 'LOJA TRATADO_ITAUCARD 2.0 CANAIS DIRETOS',\n",
       "       'LOJA TRATADO_MAGAZINE LUIZA/LUIZACRED FLEX',\n",
       "       'LOJA TRATADO_OPERACOES CREDITO CREDICARD', 'LOJA TRATADO_OUTROS',\n",
       "       'LOJA TRATADO_TAM ITAUCARD 2.0', 'status_boletagem_BOLETAR_A_PARTIR_',\n",
       "       'status_boletagem_BOLETAR_A_VONTADE', 'bandeira_CC', 'bandeira_CR',\n",
       "       'bandeira_FA', 'bandeira_FC', 'bandeira_FT', 'bandeira_HC',\n",
       "       'bandeira_LC', 'bandeira_MA', 'publico_Não definido',\n",
       "       'publico_alto_atrito', 'publico_elegivel_excecao'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dummies = pd.get_dummies(df)\n",
    "df_dummies.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Separando treino e teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    108950\n",
       "1      2470\n",
       "Name: Pagamentos, dtype: int64"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dummies['Pagamentos'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    2470\n",
       "0    2470\n",
       "Name: Pagamentos, dtype: int64"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_maioria = df_dummies[df_dummies.Pagamentos==0]\n",
    "df_minoria = df_dummies[df_dummies.Pagamentos==1]\n",
    "df_maioria_randomizado = resample(df_maioria, \n",
    "                                 replace=True,     \n",
    "                                 n_samples=2470,    \n",
    "                                 random_state=123)\n",
    "df_balanceado = pd.concat([df_maioria_randomizado, df_minoria])\n",
    "df_balanceado.Pagamentos.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = df_balanceado.pop('Pagamentos').values\n",
    "X_train = df_balanceado.values\n",
    "y_test = df_dummies.pop('Pagamentos').values\n",
    "X_test = df_dummies.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Treinando e predizendo com LogReg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.541897 using {'C': 2.0, 'dual': False, 'max_iter': 100}\n",
      "Execution time: 4.411499977111816 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\joaoc\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "param_grid_lr = {\n",
    "    'dual': [True,False],\n",
    "    'max_iter': [100,110,120,130,140],\n",
    "    'C': [1.0,1.5,2.0,2.5]\n",
    "}\n",
    "lr = LogisticRegression()\n",
    "grid_lr = GridSearchCV(estimator=lr, param_grid=param_grid_lr, cv=5, scoring='roc_auc', n_jobs=-1)\n",
    "start_time = time.time()\n",
    "grid_result = grid_lr.fit(X_train, y_train)\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "print(\"Execution time: \" + str((time.time() - start_time)) + ' ms')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = grid_result.predict_proba(X_test)\n",
    "df_predicted = df_dummies\n",
    "df_predicted['pagamentos real'] = y_test\n",
    "df_predicted['prob prevista'] = pred[:,1]\n",
    "df_predicted.to_csv('logreg_predicted.csv', decimal=',', sep=\";\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Treinando e predizendo com XgBoosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.559614 using {'min_samples_leaf': 10, 'n_estimators': 200, 'subsample': 0.6}\n",
      "Execution time: 3395.909070253372 ms\n"
     ]
    }
   ],
   "source": [
    "param_grid_xg = {\n",
    "        'n_estimators':[100,200,400,600],\n",
    "        'min_samples_leaf':[5,10,20],\n",
    "        'subsample': [0.6, 0.8, 1.0]\n",
    "        }\n",
    "xg = GradientBoostingClassifier(learning_rate=0.02)\n",
    "grid_xg = GridSearchCV(estimator=xg, param_grid=param_grid_xg, cv=5, scoring='roc_auc', n_jobs=-1)\n",
    "grid_result_xg = grid_xg.fit(X_train, y_train)\n",
    "print(\"Best: %f using %s\" % (grid_result_xg.best_score_, grid_result_xg.best_params_))\n",
    "print(\"Execution time: \" + str((time.time() - start_time)) + ' ms')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = grid_result_xg.predict_proba(X_test)\n",
    "df_predicted = df_dummies\n",
    "df_predicted['pagamentos real'] = y_test\n",
    "df_predicted['prob prevista'] = pred[:,1]\n",
    "df_predicted.to_csv(r'data\\xgboost_train_result_predict.csv', decimal=',', sep=\";\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Salvando os Scalers e o Xgboosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['models\\\\xgboosting_a03.pkl']"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(escalador_vlrcartacampanha, r\"models\\scaler_vlrcartacampanha_a03.pkl\")\n",
    "joblib.dump(escalador_vlrccluster, r\"models\\scaler_vlrcluster_a03.pkl\")\n",
    "joblib.dump(escalador_vlrdesconto, r\"models\\scaler_vlrdesconto_a03.pkl\")\n",
    "joblib.dump(grid_result_xg, r\"models\\xgboosting_a03.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### To-do"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. ~~Antes de gerar as dummies montar uma transformação para a coluna publico corrigindo: 'publico_Alto Atrito', 'publico_Eleg?¡vel Exce?º?úo', 'publico_Elegivel Excecao', 'publico_Elegível Exceção','publico_Não definido', 'publico_alto_atrito','publico_elegivel_excecao'~~\n",
    "2. ~~Ajutar a métrica para ROC~~\n",
    "3. ~~Rodar GridSearch para os hiperparâmetros da regLog e Xgboost otimizando ROC~~\n",
    "4. Selecionar o modelo e montar .py para predizer através do DW\n",
    "5. Integrar com DW para criar uma coluna com a probabilidade prevista\n",
    "6. Criar tratamento para nulos, pois eles foram retirados nessa amostra e será necessário para treinar no futuro\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
